{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QMHVIvXAmx24"
      },
      "outputs": [],
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❶ 依存ライブラリのインストール（最初だけ）\n",
        "# ────────────────────────────────────────────────\n",
        "!pip -q install --upgrade faiss-cpu sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❷ Google Drive をマウント\n",
        "# ────────────────────────────────────────────────\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nSi5NI1m07Z",
        "outputId": "c4f5b105-1812-4599-8087-3dbf3329d6b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❸ インポート\n",
        "# ────────────────────────────────────────────────\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import faiss, torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ★★ 自分の環境に合わせてここだけ書き換えてください ★★\n",
        "IMAGES_PATH = '/content/drive/MyDrive/images'        # 画像が入った最上位フォルダ\n",
        "INDEX_PATH  = '/content/drive/MyDrive/faiss_indexes/vector.index'\n",
        "TOP_K       = 5   #似ている画像を上位何件検索するかの設定です。デフォルトは5にしていますが変えても大丈夫です\n"
      ],
      "metadata": {
        "id": "qFwQ-mjIm2Eo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❹ CLIP モデルをロード\n",
        "# ────────────────────────────────────────────────\n",
        "device = 'cpu'\n",
        "model  = SentenceTransformer('clip-ViT-B-32', device=device)\n",
        "print(\"Model loaded on\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSTM-gG7m3eJ",
        "outputId": "53f486f2-bec2-4831-f540-5447e644e200"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❺ 主要関数\n",
        "# ────────────────────────────────────────────────\n",
        "def generate_clip_embeddings(images_dir: str, model):\n",
        "    exts = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.gif'}\n",
        "    image_paths = sorted(str(p) for p in Path(images_dir).rglob('*') if p.suffix.lower() in exts)\n",
        "    if not image_paths:\n",
        "        raise ValueError(f'No images found under {images_dir}')\n",
        "\n",
        "    images = [Image.open(p).convert('RGB') for p in image_paths]\n",
        "    embeddings = model.encode(\n",
        "        images, convert_to_numpy=True, normalize_embeddings=True,\n",
        "        batch_size=32, show_progress_bar=True\n",
        "    ).astype(np.float32)\n",
        "    return embeddings, image_paths\n",
        "\n",
        "\n",
        "def create_faiss_index(embeddings, paths, index_path):\n",
        "    d = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index = faiss.IndexIDMap(index)\n",
        "    index.add_with_ids(embeddings, np.arange(len(paths)))\n",
        "    faiss.write_index(index, index_path)\n",
        "    with open(index_path + '.paths', 'w') as f:\n",
        "        f.writelines(p + '\\n' for p in paths)\n",
        "    print(f'✅ Index saved to {index_path}')\n",
        "    return index\n",
        "\n",
        "\n",
        "def load_faiss_index(index_path):\n",
        "    index = faiss.read_index(index_path)\n",
        "    with open(index_path + '.paths') as f:\n",
        "        paths = [l.strip() for l in f]\n",
        "    print(f'✅ Index loaded ({len(paths)} items)')\n",
        "    return index, paths\n",
        "\n",
        "\n",
        "def retrieve_similar(query, model, index, paths, top_k=TOP_K):\n",
        "    if isinstance(query, str) and query.lower().endswith(('.png','.jpg','.jpeg','.webp','.bmp','.gif')):\n",
        "        query_img = Image.open(query).convert('RGB')\n",
        "        q_emb = model.encode(query_img, convert_to_numpy=True, normalize_embeddings=True)\n",
        "    else:\n",
        "        query_img = None\n",
        "        q_emb = model.encode(query, convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "    q_emb = q_emb.astype(np.float32).reshape(1, -1)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    return query_img, [paths[int(i)] for i in I[0]]\n",
        "\n",
        "\n",
        "def visualize(query_img, retrieved_paths):\n",
        "    n = len(retrieved_paths) + (1 if query_img else 0)\n",
        "    plt.figure(figsize=(4*n, 4))\n",
        "    col = 1\n",
        "    if query_img:\n",
        "        plt.subplot(1, n, col); col += 1\n",
        "        plt.imshow(query_img); plt.axis('off'); plt.title('Query')\n",
        "    for i, p in enumerate(retrieved_paths, 1):\n",
        "        plt.subplot(1, n, col); col += 1\n",
        "        plt.imshow(Image.open(p)); plt.axis('off')\n",
        "        plt.title(f'Result {i}\\n{Path(p).name}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "RzgHoeCXm42-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❻ インデックスを作成 (初回のみ) またはロード\n",
        "# ────────────────────────────────────────────────\n",
        "if Path(INDEX_PATH).exists():\n",
        "    index, img_paths = load_faiss_index(INDEX_PATH)      # ← 既存ファイルを使う\n",
        "else:\n",
        "    embeddings, img_paths = generate_clip_embeddings(IMAGES_PATH, model)\n",
        "    index = create_faiss_index(embeddings, img_paths, INDEX_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDAa2XLpm6aI",
        "outputId": "b4cd0f26-4ee2-4d16-9cb0-6ef36528bf61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Index loaded (518 items)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────\n",
        "# ❼ 例：検索して結果＋ファイル名を表示\n",
        "# ────────────────────────────────────────────────\n",
        "query_path = '/content/drive/MyDrive/testdata/testdata.jpg'   # 検索したい画像\n",
        "query_img, results = retrieve_similar(query_path, model, index, img_paths)\n",
        "print(\"Retrieved files:\", [Path(p).name for p in results])\n",
        "visualize(query_img, results)\n"
      ],
      "metadata": {
        "id": "xyXaSD3Wm9br"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}